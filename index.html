<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <title>Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation</title>
	<link rel="icon" type="image/x-icon" href="https://Kiss3DGen.github.io/assets/css/images/favicon.ico">
    <meta content="Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="static/css/index.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
    <script type="module" src="static/js/model-viewer.min.js"></script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">Kiss3DGen:<br /> Repurposing Image Diffusion Models for 3D Asset Generation</h1>
            <div class="nerf_subheader_v2">
                <div>
                    <h1 class="nerf_affiliation_v2"><a href="https://scholar.google.cz/citations?hl=zh-CN&user=ri-snP0AAAAJ" target="_blank">Jiantao Lin</a></h1><sup>1</sup><strong>*</strong>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2"><a href="https://abnervictor.github.io/2023/06/12/Academic-Self-Intro.html" target="_blank">Xin Yang</a></h1><sup> 1,2</sup><strong>*</strong>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2"><a href="https://scholar.google.com/citations?user=ggfkeMEAAAAJ&hl=en" target="_blank">Meixi Chen</a></h1><sup> 1</sup><strong>*</strong>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Yingjie Xu</h1><sup> 1</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Dongyu Yan</h1><sup> 1</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Leyi Wu</h1><sup> 1</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Xinli Xu</h1><sup> 1</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Lie XU</h1><sup> 3</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Shunsi Zhang</h1><sup> 3</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2"><a href="https://www.yingcong.me/" target="_blank">Ying-Cong Chen</a></h1><sup> 1,2</sup><strong>†</strong>,&nbsp;&nbsp;
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1 </sup>HKUST(GZ)</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>2 </sup>HKUST</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>3 </sup>Guangzhou Quwan Network Technology</h1>
                </div>
                <div style="display: flex; justify-content: center; align-items: center; gap: 10px; text-align: center;">
                    <p style="margin: 0;">* Equal contribution</p>
                    <p style="margin: 0;">† Corresponding author</p>
                </div>

                <div class="external-link">
                    <a class="btn" href="https://arxiv.org/pdf/2503.01370" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" href="https://huggingface.co/spaces/LTT/Kiss3DGen" role="button" target="_blank">
                        <i class="fa-solid fa-chess-knight"></i> Demo (HF) </a> 
                    <a class="btn" href="" role="button" target="_blank">
                        <i class="fa-solid fa-chess-knight"></i> Demo (Gradio) </a>
                    <a class="btn" href="" role="button" target="_blank">
                        <i class="fa-solid fa-chess-knight"></i> Demo (Local) </a>  
                    <a class="btn" href="https://github.com/EnVision-Research/Kiss3DGen" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                </div>
                <p></p>In collaboration with Quwan, this project has been successfully commercialized and is now available for real-world applications (See <a href="https://gen3d.funnycp.com" target="_blank">趣丸万相</a> for details). We are truly grateful to Quwan for their support, especially in data and engineering, which were key to this achievement.</p>
                
            </div>
        </div>
    </div>

    <center>
        <video src="assets/teaser_video.mp4" controls style="max-width: 100%; width: 1000px; height: auto;"></video>
    </center>
    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                Diffusion models have achieved great success in generating 2D images. However, the quality and generalizability of 3D content generation remain limited. State-of-the-art methods often require large-scale 3D assets for training, which are challenging to collect. In this work, we introduce Kiss3DGen (Keep It Simple and Straightforward in 3D Generation), an efficient framework for generating, editing, and enhancing 3D objects by repurposing a well-trained 2D image diffusion model for 3D generation. Specifically, we fine-tune a diffusion model to generate "3D Bundle Image", a tiled representation composed of multi-view images and their corresponding normal maps. The normal maps are then used to reconstruct a 3D mesh, and the multi-view images provide texture mapping, resulting in a complete 3D model. This simple method effectively transforms the 3D generation problem into a 2D image generation task, maximizing the utilization of knowledge in pretrained diffusion models. Furthermore, we demonstrate that our Kiss3DGen model is compatible with various diffusion model techniques, enabling advanced features such as 3D editing, mesh and texture enhancement, etc. Through extensive experiments, we demonstrate the effectiveness of our approach, showcasing its ability to produce high-quality 3D models efficiently.
                <br>
            </p>
        </div>
    </div>
    
    <!-- Text-to-Mesh Section -->
    <div class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf" style="text-align: center;">Text-to-Mesh</h2>
            <div id="text-to-mesh-container"></div>
            <div style="text-align: center; margin-top: 20px;">
                <button id="more-results-button-text" style="
                padding: 10px 20px; 
                font-size: 16px; 
                cursor: pointer; 
                background-color: #007BFF; /* 按钮背景色 */
                color: white; /* 字体颜色 */
                border: none; 
                border-radius: 5px; /* 圆角效果 */
                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); /* 阴影效果 */
                transition: all 0.3s ease;">More Results</button>
            </div>
        </div>
    </div>

    <!-- Script to Load JSON and Populate the Section -->
    <script>
        // Load Text-to-Mesh Data
        fetch('assets/text_to_3d.json') // 替换为你的 JSON 文件路径
            .then(response => response.json())
            .then(data => {
                const container = document.getElementById('text-to-mesh-container');
                const moreButton = document.getElementById('more-results-button-text');
                const maxRowsToShow = 2; // 默认显示的行数
                const itemsPerRow = 2; // 每行显示的项目数
                const maxItemsToShow = maxRowsToShow * itemsPerRow; // 默认显示的项目数量

                let allKeys = Object.keys(data); // 获取所有 JSON 键
                let isShowingAll = false; // 标志是否显示所有内容

                // 设置父容器样式，确保弹性布局
                container.style.display = "flex";
                container.style.flexWrap = "wrap"; // 允许内容换行
                container.style.gap = "20px"; // 设置块之间的间距
                container.style.justifyContent = "center"; // 居中对齐

                // 渲染内容
                function renderContent(keys) {
                    container.innerHTML = ""; // 清空容器内容
                    keys.forEach(key => {
                        const block = document.createElement('div');
                        block.style.flex = "0 0 calc(50% - 20px)"; // 每行 2 个视频
                        block.style.boxSizing = "border-box"; // 包含内边距和边框
                        block.style.textAlign = "center"; // 内容居中对齐

                        // 动态生成内容
                        block.innerHTML = `
                            <p style="font-size: 14px; margin-bottom: 10px;"><strong>${data[key]}</strong></p>
                            <video controls loop autoplay muted style="max-width: 100%; width: 100%; height: auto;">
                                <source src="assets/text_to_mesh/${key}.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                        `;
                        container.appendChild(block);
                    });
                }

                // 默认显示部分内容
                renderContent(allKeys.slice(0, maxItemsToShow));

                // 点击按钮显示所有内容
                moreButton.addEventListener('click', () => {
                    if (!isShowingAll) {
                        renderContent(allKeys); // 显示所有内容
                        moreButton.innerText = "Show Less"; // 按钮文本切换
                        isShowingAll = true;
                    } else {
                        renderContent(allKeys.slice(0, maxItemsToShow)); // 显示部分内容
                        moreButton.innerText = "More Results"; // 按钮文本切换
                        isShowingAll = false;
                    }
                });
            })
            .catch(error => console.error('Error loading JSON:', error));
    </script>

    <!-- Image-to-Mesh Section -->
    <div class="section nerf_section">
        <div class="w-container grey_container" style="display: flex; flex-direction: column; align-items: center;">
            <h2 class="grey-heading_nerf" style="text-align: center;">Image-to-Mesh</h2>
    
            <!-- 顶部标题，与下方内容对齐 -->
            <div style="display: flex; justify-content: space-between; align-items: center; gap: 20px; width: 100%; max-width: 1200px; margin-bottom: 20px;">
                <div style="flex: 1; text-align: center;">
                    <p><strong>Input Image</strong></p>
                </div>
                <div style="flex: 1; text-align: center;">
                    <p><strong>Generated Mesh</strong></p>
                </div>
            </div>
    
            <!-- 容器 -->
            <div id="img-to-mesh-container" style="display: flex; flex-direction: column; gap: 40px; align-items: center; width: 100%;"></div>
    
            <!-- 按钮 -->
            <div style="text-align: center; margin-top: 20px;">
                <button id="more-results-button-img" style="
                    padding: 10px 20px; 
                    font-size: 16px; 
                    cursor: pointer; 
                    background-color: #007BFF; /* 按钮背景色 */
                    color: white; /* 字体颜色 */
                    border: none; 
                    border-radius: 5px; /* 圆角效果 */
                    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); /* 阴影效果 */
                    transition: all 0.3s ease;">More Results</button>
            </div>
        </div>
    </div>
    
    <!-- Scripts to Dynamically Generate Image and Video Pairs -->
    <script>
        const inputImageFolder = "assets/input_image/";
        const videoFolder = "assets/image_to_mesh/";
    
        // 示例文件列表
        const files = [
            "beer", 
            "blue_monster",
            "bottle",
            "castle2",
            "cat1",
            "dargon",
            "mushroom_teapot"
        ];
    
        const container = document.getElementById("img-to-mesh-container");
        const moreButton = document.getElementById("more-results-button-img");
    
        const maxRowsToShow = 3; // 默认显示的行数
        const isShowingAll = { value: false }; // 当前显示状态，使用对象以便共享
    
        // 渲染内容
        function renderContent(showAll) {
            container.innerHTML = ""; // 清空内容
            const maxItemsToShow = showAll ? files.length : maxRowsToShow; // 显示全部或限制行数
    
            files.slice(0, maxItemsToShow).forEach(filename => {
                // 创建一个包裹图片和视频的容器
                const block = document.createElement("div");
                block.style.display = "flex"; // 水平排列
                block.style.flexDirection = "row"; // 强制水平排列
                block.style.justifyContent = "space-between"; // 左右分布
                block.style.alignItems = "center"; // 垂直居中
                block.style.width = "100%"; // 占据整行
                block.style.maxWidth = "1200px"; // 限制最大宽度
                block.style.gap = "20px"; // 图片和视频之间的间距
    
                // 动态生成内容
                block.innerHTML = `
                    <!-- 输入图片 -->
                    <div style="flex: 1; text-align: center;">
                        <img src="${inputImageFolder}${filename}.png" alt="Input Image" style="max-height: 256px; width: auto; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.2);">
                    </div>
    
                    <!-- 视频 -->
                    <div style="flex: 1; text-align: center;">
                        <video controls loop autoplay muted style="width: 512px; height: 256px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.2);">
                            <source src="${videoFolder}${filename}.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                `;
    
                // 将容器添加到主显示区域
                container.appendChild(block);
            });
    
            // 按钮状态更新
            moreButton.innerText = showAll ? "Show Less" : "More Results";
            moreButton.style.backgroundColor = showAll ? "#DC3545" : "#007BFF";
            isShowingAll.value = showAll;
        }
    
        // 初始化内容
        renderContent(false);
    
        // 按钮点击事件
        moreButton.addEventListener("click", () => {
            renderContent(!isShowingAll.value);
        });
    </script>
    


    <div class="white_section_nerf w-container">
        <h2 class="grey-heading_nerf">Mesh Refinement Gallery</h2>
        
        <div class="grid-container-3">
            <!-- 第一行（默认显示） -->
            <div>
                <video class="video" id="chicken" loop playsinline autoPlay muted
                src="assets/refined_mesh/chicken.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="chicken_merge"></canvas>
            </div>
            <div>
                <video class="video" id="day_235_roadster_edit-2" loop playsinline autoPlay muted
                src="assets/refined_mesh/day_235_roadster_edit-2.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="day_235_roadster_edit-2_merge"></canvas>
            </div>
            <div>
                <video class="video" id="coarse-man2" loop playsinline autoPlay muted
                src="assets/refined_mesh/coarse-man2.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="coarse-man2_merge"></canvas>
            </div>
    
            <!-- 隐藏内容（默认隐藏） -->
            <div class="hidden">
                <video class="video" id="orange-blue-girl-in-hood-kiss" loop playsinline autoPlay muted
                src="assets/refined_mesh/orange-blue-girl-in-hood-kiss.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="orange-blue-girl-in-hood-kiss_merge"></canvas>
            </div>
            <div class="hidden">
                <video class="video" id="day_235_roadster_edit-1" loop playsinline autoPlay muted
                src="assets/refined_mesh/day_235_roadster_edit-1.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="day_235_roadster_edit-1_merge"></canvas>
            </div>
            <div class="hidden">
                <video class="video" id="coarse-man1" loop playsinline autoPlay muted
                src="assets/refined_mesh/coarse-man1.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="coarse-man1_merge"></canvas>
            </div>
            <div class="hidden">
                <video class="video" id="pink-yellow-girl-in-hood-kiss" loop playsinline autoPlay muted
                src="assets/refined_mesh/pink-yellow-girl-in-hood-kiss.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="pink-yellow-girl-in-hood-kiss_merge"></canvas>
            </div>
            <div class="hidden">
                <video class="video" id="stalin-1" loop playsinline autoPlay muted
                src="assets/refined_mesh/stalin-1.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="stalin-1_merge"></canvas>
            </div>
            <div class="hidden">
                <video class="video" id="stalin-2" loop playsinline autoPlay muted
                src="assets/refined_mesh/stalin-2.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="stalin-2_merge"></canvas>
            </div>
        </div>
        
        <!-- 按钮 -->
        <div style="text-align: center; margin-top: 20px;">
            <button id="more-results-button-refine" style="
                padding: 10px 20px; 
                font-size: 16px; 
                cursor: pointer; 
                background-color: #007BFF; 
                color: white; 
                border: none; 
                border-radius: 5px; 
                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); 
                transition: all 0.3s ease;">More Results</button>
        </div>
    </div>


    <!-- <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/overview.png">

            <p> Our method first transforms the input single image or text prompt into multi-view images using a multi-view diffusion model.
                These generated multi-view images are then fed into a native 3D diffusion model as conditions to produce a coarse mesh with regular topology. Finally, a
                surface normal-based refinement is employed to improve or edit the coarse geometry, enhancing it with intricate details. The refinement process features two
                key tools: an automatic global refinement and an interactive Magic Brush, which together enable efficient and controllable 3D modeling.
            </p>
        </div>
    </div> -->



<div class="white_section_nerf grey_container w-container">
<h2 class="grey-heading_nerf">BibTeX</h2>
<div class="bibtex">
    <pre><code>
        @article{lin2025kiss3dgenrepurposingimagediffusion,
            title={Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation},
            author={Jiantao Lin, Xin Yang, Meixi Chen, Yingjie Xu, Dongyu Yan, Leyi Wu, Xinli Xu, Lie XU, Shunsi Zhang, Ying-Cong Chen},
            journal={arXiv preprint arXiv:2503.01370},
            year={2025}
          }
    </code></pre>
</div>
</div>
<script>
    document.addEventListener("DOMContentLoaded", () => {
        const moreButton = document.getElementById('more-results-button-refine');
        const hiddenItems = document.querySelectorAll('.hidden');

        moreButton.addEventListener('click', () => {
            hiddenItems.forEach(item => {
                item.classList.toggle('hidden');
            });

            if (moreButton.innerText === "More Results") {
                moreButton.innerText = "Show Less";
            } else {
                moreButton.innerText = "More Results";
            }
        });
    });
</script>
</body>
<footer>
    We would like to thank Hanfen Zhao and Guoliang Pang for their engineering support.
</footer>
<footer>
    This project page is inspired by <a href="https://craftsman3d.github.io/">CraftsMan3D.</a>, © Weiyu Li. All rights reserved.
</footer>

</html>
